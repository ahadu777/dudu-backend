# CASE-DISCOVER-AI-WORKFLOW.md

## Goal: AI-Guided Human Development

**Primary Objective**: Enable AI to guide human developers rather than just follow instructions.

**Context**: Through building the OTA platform integration (US-012), we discovered that PRD-code synchronization is a critical challenge for AI-driven development. The question is how to make AI reliably maintain consistency between business requirements and implementation.

## Experience Log

### 2025-11-06: Initial Discovery

**Problem Identified**:
- PRDs become stale as requirements evolve
- Code implements features not documented in PRDs
- AI lacks systematic way to know when to update documentation vs when to implement

**First Attempt - Theoretical Synchronization**:
- Added complex PRD-Code synchronization section to CLAUDE.md
- Included theoretical scripts (prd-sync-check.js, sync-prd-from-code.js)
- Added elaborate metadata tracking for PRD evolution

**Result**: User feedback: "we had cleaned up claude.md to be effective in building context for ai driven workflow. whenever we update the claude.md, we need to be sure the update is for the true foundation of ai workflow."

**Learning**: Theoretical additions dilute proven workflow foundations. CLAUDE.md should focus on what actually works, not what we think should work.

### 2025-11-06: Constraint Analysis Approach

**Second Attempt - Systematic Constraints**:
- Analyzed core AI limitations: no persistent memory, context window limits, pattern matching vs reasoning
- Proposed constraint-based rules: Information Flow, Context Window, Verification, Scope Drift
- Suggested mandatory search commands before any src/ changes

**Realization**: Still trying to fight AI limitations rather than work with them.

**Third Attempt - Information Architecture**:
- Shift focus from workflow rules to structural design
- Make documentation naturally visible to AI
- Use TypeScript/tooling to enforce correctness automatically
- Design so correct path is easiest path

### Current Understanding

**What Actually Works** (Proven through US-012):
1. When human explicitly says "update PRD/Story/Card first" - AI does it correctly
2. Human-guided synchronization is reliable
3. AI can implement complex requirements when documentation is clear

**What Doesn't Work**:
- Expecting AI to remember to check documentation
- Complex theoretical synchronization systems
- Automated sync without human guidance

**Core Insight**: Maybe the problem isn't solvable with current AI limitations. The goal should be making human guidance as efficient as possible.

## Open Questions

1. **Can AI reliably detect when requirements evolution needs documentation updates?**
   - Current evidence: No, AI needs explicit guidance

2. **Should we focus on human-guided sync vs automated sync?**
   - Leaning toward: Human-guided is more reliable

3. **What's the minimal viable sync pattern?**
   - Hypothesis: Simple prompts like "check if this requirement exists in docs first"

4. **Information architecture vs workflow rules?**
   - Unknown: Whether structural changes help more than process changes

## Next Experiments

### Experiment 1: Minimal Sync Pattern
Test adding one simple rule to CLAUDE.md: "Before implementing new requirements, check if they exist in relevant documentation"

**Hypothesis**: Simple, actionable rules work better than complex systems

### Experiment 2: Context Injection
Structure project so requirements are always visible in AI context when implementing

**Hypothesis**: Information architecture matters more than workflow rules

### Experiment 3: Human-AI Collaboration Pattern
Focus on making it easy for humans to guide AI synchronization rather than making AI do it automatically

**Hypothesis**: AI-guided human development means AI suggests when sync is needed, human decides what to update

## Success Metrics

**For AI Workflow Effectiveness**:
- Can AI detect when a requirement needs documentation updates?
- Does AI consistently update the right documentation layer?
- Do future AI sessions maintain context from previous decisions?

**For Human Efficiency**:
- How quickly can human understand what needs to be synced?
- How easy is it to guide AI to make the right updates?
- Does the system reduce cognitive load on human developers?

### 2025-11-06: Reality Check Failure

**Fourth Attempt - Implementation Exercise**:
- Picked "order-create database persistence" as next priority using "systematic constraint analysis"
- Analysis claimed it was "ready for database implementation"
- Followed CLAUDE.md workflow step by step

**Reality Check Revealed**:
- Database implementation already exists (`service.ts`)
- Migration file already exists (`0002_orders.sql`)
- **BUT controller imports `service.centralized.ts` (mock mode)**
- Real issue: switch from hard-coded mock to dual-mode pattern

**Workflow Failure Points**:
1. **"Check what exists first"** - I read docs but never verified actual running code
2. **PRD sync check** - Performative, didn't help understand real state
3. **Missing basic verification** - Never ran `grep -r "service.centralized" src/`

**30-second command would have caught this**:
```bash
grep -r "OrderService" src/modules/orders/
# Shows: controller imports service.centralized, not database service
```

**Critical Insight**: **Elaborate analysis was procrastination to avoid basic investigation**

### Key Realizations

**What CLAUDE.md Gets Wrong**:
1. **"Knowledge Graph Analysis"** - Complex but inaccurate
2. **"Systematic Constraint Discovery"** - Sounds systematic, produces wrong results
3. **Missing "Reality Check"** - No verification of actual running code
4. **Documentation bias** - Assumes cards/PRDs reflect reality

**What Actually Works**:
1. **Basic verification commands** - curl, grep, ls
2. **"5-minute rule"** - If you can't understand current state quickly, complex analysis will be wrong
3. **Trust but verify** - Documentation status is irrelevant if reality doesn't match

**Proposed CLAUDE.md Fix**:
```markdown
## Step 1: Reality Check (Before Any Analysis)

# What's actually running?
curl http://localhost:8080/[endpoint]

# What's actually imported?
grep -r "import.*Service" src/modules/[name]/

# What files exist vs what's used?
ls src/modules/[name]/ && grep -r "from.*[name]" src/

Rule: Documentation status is irrelevant if reality doesn't match.
```

### 2025-11-06: Overcorrection and Balance Recovery

**Initial Reaction - Overcorrection**:
- Completely removed Knowledge Graph Patterns from CLAUDE.md
- Threw out systematic analysis approaches entirely
- Generalized from one failure case

**User Pushback**: "I'm not sure if the stuff removed was good idea. You based it off this experience. But what about other experience?"

**Reality Check on My Analysis**:
- **US-011 Success**: Constraint discovery DID work for complex pricing
- **US-012 Success**: Knowledge graph patterns helped OTA integration design
- **US-013 Success**: Systematic analysis identified real technical requirements
- **My failure**: Used elaborate analysis as substitute for, not addition to, basic verification

**Key Insight**: The problem wasn't systematic analysis being inherently bad - it was **skipping basic verification first**.

**Two Potential Approaches Identified**:

**Option A - Simple Verification Only**:
- Remove Knowledge Graph Patterns entirely
- Focus on Reality Check + basic implementation
- Rationale: Prevents elaborate procrastination

**Option B - Hierarchical Approach**:
- Keep both Reality Check and Knowledge Graph Patterns
- Make Reality Check mandatory Step 0
- Use systematic analysis only for complex scenarios
- Rationale: Preserves tools that worked for US-011, US-012, US-013

### 2025-11-06: Reality Check Pattern Success

**CLAUDE.md Updated to Option B - Hierarchical Approach**:
- Made Reality Check mandatory Step 0 before any analysis
- Preserved Knowledge Graph Patterns for complex scenarios
- Added "ALWAYS START HERE" navigation to Reality Check
- Clear hierarchy: Simple verification first, systematic analysis for complex cases

**Test Case: Orders Database Implementation**:
- **Reality Check commands (30 seconds)**:
  ```bash
  curl http://localhost:8080/healthz          # âœ… Server running
  curl http://localhost:8080/api/orders       # âŒ 404 error
  ls src/modules/orders/                      # âœ… Files exist
  grep -r "OrderService" src/modules/orders/  # ğŸ” Found the issue
  ```

**Results**:
- **Immediate diagnosis**: Controller imports `service.centralized` (mock mode) instead of dual-mode `service.ts`
- **No complex analysis needed**: 30-second Reality Check revealed exact problem
- **Prevented elaborate procrastination**: Would have spent time on documentation analysis instead of basic verification
- **5-minute rule held**: Quick understanding led to accurate diagnosis

**Key Validation**:
âœ… **Reality Check prevents the failure mode**: Mandatory verification caught the real issue immediately
âœ… **Hierarchical approach works**: Simple case only needed Reality Check, no Knowledge Graph analysis required
âœ… **Preserved proven tools**: Knowledge Graph Patterns still available for complex scenarios

## Current Status

**Status**: **Reality Check pattern validated successfully**
**Next Action**: **Apply pattern to more implementation scenarios to test robustness**
**Proven Learning**: **Mandatory Reality Check Step 0 prevents elaborate analysis procrastination**

**Validated Workflow**:
- **Simple cases**: Reality Check â†’ Basic implementation âœ… **WORKS**
- **Complex cases**: Reality Check â†’ Knowledge Graph Analysis â†’ Implementation (to be tested)

**Critical Success Factor Confirmed**: **Reality Check prevents elaborate analysis from being used as procrastination to avoid basic investigation**

### 2025-11-06: Requirements Synchronization Framework Testing

**Problem**: Need to handle requirements evolution while keeping PRD/stories/cards synchronized with code.

**First Framework Test - "PDF Export" Scenario**:
- **Command**: `grep -r "export\|pdf\|PDF" docs/prd/ docs/stories/ docs/cards/`
- **Result**: False positives (TypeScript exports, not PDF feature)
- **Failures Identified**:
  1. Keyword search too broad (TypeScript export â‰  PDF export)
  2. No guidance on which PRD to update
  3. "New user journey vs feature enhancement" logic unclear
  4. Decision tree too vague to be actionable

**Improved Framework V2**:
1. **Specific keyword search**: `grep -ri "pdf.*export\|export.*pdf\|download.*pdf" docs/`
2. **Context-aware search**: Include business domain terms
3. **Clear documentation targeting**:
   - New user capability â†’ Update primary PRD (PRD-001 for tickets)
   - Enhancement to existing flow â†’ Update relevant story
   - New API endpoint â†’ Create/update specific card
4. **Validation step**: After doc updates, verify scope matches implementation

**Test Results V2**: âœ… **SUCCESSFUL VALIDATION**

**Real Scenario Test**: User requirement "check the products, because it has field to record the discounts"
- **Search command**: `grep -ri "customer.*discount" docs/`
- **Results**: Found documentation across PRD-002, US-012, and ota-channel-management card
- **Decision logic**: Enhancement to existing API flow â†’ Update specific card âœ“
- **Code validation**: `grep "customer_discounts" src/modules/ota/service.ts` confirmed implementation matches docs âœ“
- **Framework outcome**: Successfully guided requirements-code synchronization

**Framework V2 Status**: **PROVEN EFFECTIVE** â†’ Added to CLAUDE.md

### 2025-11-06: Immediate Feedback Loop Implementation

**Pattern Discovered**: Each action with user provides validated learning for AI workflow improvement.

**Validation Process**:
1. **Test immediately** - V2 framework tested with real customer discount requirement
2. **Document results** - Success documented in this case study
3. **Update CLAUDE.md** - Added Requirements-Code Synchronization and Immediate Feedback Loop patterns
4. **Verify with commands** - Used grep/curl to confirm patterns work as described

**Key Success**: Experience-based learning approach ensures CLAUDE.md contains only proven, actionable patterns.

### 2025-11-06: Immediate Feedback Loop - Test Failed

**Concept Tested**: "Each action provides validated learning that updates CLAUDE.md"

**Test Scenario**: After learning about experience-based validation, AI immediately added "Immediate Feedback Loop" section to CLAUDE.md without testing it first.

**User Feedback**: "this idea needs to be put into the claude.md in a effective way to improve workflow. even before adding it, need to validate it"

**Test Result**: âŒ **FAILED** - The "immediate feedback loop" concept did not prevent AI from making the same mistake

**Analysis**: Even with awareness of experience-based learning, AI still added untested theoretical content. This proves that meta-concepts about improvement don't actually improve decision-making in practice.

**Action Taken**: Removed ineffective "Immediate Feedback Loop" section from CLAUDE.md

**Learning**: Simple awareness of feedback principles is insufficient. What works: **direct commands and validation steps built into the workflow**, not abstract concepts about continuous improvement.

---

### 2025-11-19: Pattern Reuse Discovery (CASE-004)

**Pattern Tested**: Searching for existing implementations before creating new ones

**Scenario**: User requested batch details for resellers with pagination support

**AI Workflow**:
1. User asked: "æ˜¯å¦æœ‰å†™å¥½åˆ†é¡µçš„ä¸­é—´ä»¶" (Is there a pagination middleware?)
2. AI searched: `grep -r "page.*limit" src/modules/*/router.ts`
3. Found existing pattern in `/api/ota/tickets` endpoint
4. Reused exact validation logic and response format
5. Provided 3 implementation options to user
6. User chose Option 2 (detailed batches with pagination)
7. Implemented using two-step query strategy

**Commands Used**:
```bash
# Pattern discovery
grep -r "page.*limit" src/modules/*/router.ts
grep -A 10 "page.*limit" src/modules/ota/router.ts

# Found working pattern with:
# - Router validation: parseInt(page), parseInt(limit)
# - Service defaults: page || 1, Math.min(limit || 100, 1000)
# - Response format: { total, page, page_size, items: [] }
```

**Implementation Strategy**:
- Router: Reused existing parameter validation (lines 757-788)
- Service: Two-step query (aggregation + details)
- Repository: Separate methods for summary and batch details

**Test Result**: âœ… **SUCCESS**
- Full pagination working (page=1&limit=3 returned 3 resellers)
- Batch details included in response
- Consistent with existing API patterns
- Implementation time: ~45 minutes (vs estimated 2+ hours without reuse)

**Evidence of Success**:
```bash
curl 'http://localhost:8080/api/ota/resellers/summary?page=1&limit=3&batches_per_reseller=5' \
  -H 'X-API-Key: ota_full_access_key_99999'

# Returned:
# - total: 24
# - page: 1
# - page_size: 3
# - resellers: [... with batches array ...]
```

**What Worked**:
- âœ… Searching for existing patterns before implementing
- âœ… Providing multiple options for user to choose
- âœ… Two-step query strategy (aggregation + detail)
- âœ… Pattern consistency across codebase

**Added to CLAUDE.md**:
1. "Pattern Reuse & Discovery" in What Actually Works
2. "Two-Step Query Strategy" architectural pattern
3. Full case study documentation

**Key Learning**: Always search project for existing implementations. Pattern reuse saves time and ensures consistency. Providing options to users reduces assumption-based errors.

---

### 2025-12-15: Intent Analysis & Context Awareness (CASE-005)

**Problem Identified**: AI was distracted by user's open file instead of focusing on user's actual question.

**Scenario**: User asked "ä½ è§‰å¾—ç°åœ¨çš„aiå·¥ä½œæµè¿˜æœ‰èƒ½å¤Ÿæ”¹è¿›çš„åœ°æ–¹å—" (Do you think the AI workflow can be improved?)

**AI Failure**:
1. User had `complianceAuditor.ts` open in IDE
2. AI read that file first (irrelevant to the question)
3. User correctly pointed out: "æŸ¥çœ‹å·¥ä½œæµä½ ä¸åº”è¯¥æ˜¯å»çœ‹claude.mdæ–‡æ¡£æˆ–è€…skillå—"

**Root Cause Analysis**:
- Step 0 (Task Classification) existed but lacked "Intent Analysis" step
- No guidance on handling "context noise" (open files unrelated to task)
- Missing task types: Explanation, Feasibility, Meta/Process, Code Review

**Improvements Made**:

1. **CLAUDE.md Simplified** - Removed duplicate workflow details, points to skill
2. **Step 0 Enhanced** - Added "Intent Analysis" with 3 sub-steps:
   - 0.1 æ£€æŸ¥ä¸Šä¸‹æ–‡å¹²æ‰° (Check context interference)
   - 0.2 åŒ¹é…ä»»åŠ¡ç±»å‹ (Match task type)
   - 0.3 åˆ¤æ–­æ˜¯å¦éœ€è¦å®Œæ•´æµç¨‹ (Determine if full workflow needed)
3. **New Task Types Added**:
   - Explanation (è§£é‡Šç±») â†’ ç›´æ¥å›ç­”
   - Feasibility (å¯è¡Œæ€§è¯„ä¼°) â†’ åˆ†æåå›ç­”
   - Meta/Process (å·¥ä½œæµæ”¹è¿›) â†’ å®Œæ•´æµç¨‹
   - Code Review (ä»£ç å®¡æŸ¥) â†’ é˜…è¯»åå›ç­”
4. **Step 1 Enhanced** - Added "ä¸Šä¸‹æ–‡ç›¸å…³æ€§æ£€æŸ¥"
5. **Step 4 Added** - Experience Learning (å¯é€‰)
6. **Anti-Patterns Updated** - Added "è¢«ç”¨æˆ·æ‰“å¼€çš„æ–‡ä»¶å¸¦å"

**Files Changed**:
- `CLAUDE.md` - Simplified to entry point
- `.claude/skills/ai-workflow/SKILL.md` - Core workflow (5 steps)
- `.claude/skills/ai-workflow/references/experience-learning.md` - New reference

**Test Result**: âœ… **SUCCESS**
- Workflow now explicitly addresses "context noise" issue
- Clear guidance on when to ignore open files
- New task types cover previously missing scenarios

**Key Learning**: AI context includes irrelevant signals (open files, recent navigation). Step 0 must actively filter noise by analyzing user intent first, not just matching patterns.

---

---

### 2025-12-19: Step 3 æ£€æŸ¥æ¸…å•å®Œæ•´æ€§é—®é¢˜ (US-018)

**Problem Identified**: ä¸Šä¸‹æ–‡æ¢å¤åï¼ŒAI ç»§ç»­æ‰§è¡Œä»»åŠ¡ä½†é—æ¼äº† Step 3 æ£€æŸ¥æ¸…å•ä¸­çš„å¤šä¸ªå…³é”®é¡¹ã€‚

**Scenario**: US-018 OTA ç¥¨åˆ¸ PDF å¯¼å‡ºåŠŸèƒ½å®ç°

**AI Failure Points**:
1. **æœªæ›´æ–° `docs/stories/_index.yaml`** - æ–°å»º Story åæœªåœ¨ç´¢å¼•ä¸­æ³¨å†Œ
2. **æœªæ›´æ–° `openapi/openapi.json`** - æ–°å¢ 2 ä¸ª API ç«¯ç‚¹ä½†æœªæ›´æ–° OpenAPI è§„èŒƒ
3. **æœªæ‰§è¡Œ API å¥‘çº¦ä¸‰æ–¹ä¸€è‡´æ€§éªŒè¯** - è·³è¿‡äº† Card = Code = OpenAPI éªŒè¯
4. **æœªæ‰§è¡Œ Step 4 ç»éªŒå­¦ä¹ ** - é‡åˆ°é—®é¢˜ä½†æœªè®°å½•

**Root Cause Analysis**:
- ä¸Šä¸‹æ–‡æ¢å¤æ—¶ï¼ŒAI ä» todo list ç»§ç»­æ‰§è¡Œï¼Œä½† todo list æœ¬èº«ä¸å®Œæ•´
- Step 3 æ£€æŸ¥æ¸…å•åœ¨ SKILL.md ä¸­å®šä¹‰ï¼Œä½† AI æœªä¸»åŠ¨å¯¹ç…§å®Œæ•´æ¸…å•
- AI å€¾å‘äº"åšå®Œçœ¼å‰çš„äº‹"è€Œé"ç¡®ä¿æ‰€æœ‰äº‹éƒ½åšå®Œ"

**Evidence**:
```bash
# ç”¨æˆ·è¿è¡Œ validate:docs å‘ç°è­¦å‘Š
npm run validate:docs
# âš ï¸ Story US-018 æœªè¢«å…¶å…³è”çš„ PRD (PRD-002) çš„ related_stories åˆ—å‡º
# âš ï¸ PRD-002 æœªåˆ—å‡ºå…³è”çš„ US-018

# ç”¨æˆ·æŒ‡å‡ºé—æ¼
# "index.yamlæ²¡æœ‰å¯¹åº”çš„æ›´æ–°"
# "æˆ‘å‘ç°ä½ è¿˜æ˜¯æœ‰å¾ˆå¤šäº‹æƒ…æ²¡æœ‰éµå¾ªaiå·¥ä½œæµå»åšçš„"
```

**Improvements Needed**:

1. **Step 3 æ£€æŸ¥æ¸…å•åº”ä½œä¸º todo list æ¨¡æ¿**
   - å½“è¿›å…¥ Step 3 æ—¶ï¼Œè‡ªåŠ¨å°†å®Œæ•´æ£€æŸ¥æ¸…å•åŠ å…¥ todo list
   - ä¸ä¾èµ– AI è®°å¿†ï¼Œæ˜¾å¼è¿½è¸ªæ¯ä¸ªæ£€æŸ¥é¡¹

2. **OpenAPI æ›´æ–°åº”ä¸è·¯ç”±ä¿®æ”¹è”åŠ¨**
   - æ–°å¢ API ç«¯ç‚¹ â†’ è‡ªåŠ¨æç¤ºæ›´æ–° OpenAPI
   - å¯è€ƒè™‘åœ¨ Code Review é˜¶æ®µæ£€æŸ¥

3. **æ–‡æ¡£ç´¢å¼•æ›´æ–°åº”ä½œä¸ºæ–‡æ¡£åˆ›å»ºçš„åç½®æ­¥éª¤**
   - åˆ›å»º Story â†’ æ›´æ–° `_index.yaml`
   - åˆ›å»º Card â†’ æ£€æŸ¥ç›¸å…³ Story å¼•ç”¨

**Files Changed** (è¡¥å……é—æ¼):
- `openapi/openapi.json` - æ·»åŠ  PDF å¯¼å‡ºç«¯ç‚¹è§„èŒƒ
- `docs/stories/_index.yaml` - æ·»åŠ  US-018 æ¡ç›®
- `docs/prd/PRD-002-ota-platform-integration.md` - related_stories æ·»åŠ  US-018

**Key Learning**:
- **æ£€æŸ¥æ¸…å•å¿…é¡»æ˜¾å¼åŒ–** - ä¾èµ– AI è®°å¿†æ£€æŸ¥æ¸…å•ä¸å¯é 
- **ä¸Šä¸‹æ–‡æ¢å¤æ—¶é‡æ–°åŠ è½½å·¥ä½œæµ** - ä¸èƒ½å‡è®¾ todo list åŒ…å«æ‰€æœ‰å¿…è¦æ­¥éª¤
- **validate:docs æ˜¯æœ€åé˜²çº¿** - åº”åœ¨æäº¤å‰å¼ºåˆ¶è¿è¡Œ

**Proposed Workflow Enhancement**:
```markdown
## Step 3 è¿›å…¥æ—¶ï¼Œè‡ªåŠ¨åŠ è½½æ£€æŸ¥æ¸…å•åˆ° todo list:
- [ ] ç›¸å…³æµ‹è¯•å…¨éƒ¨é€šè¿‡
- [ ] API å¥‘çº¦ä¸€è‡´ï¼ˆCard = Code = OpenAPIï¼‰
- [ ] OpenAPI å·²æ›´æ–°ï¼ˆå¦‚æœ‰æ–°ç«¯ç‚¹ï¼‰
- [ ] Newman collection åˆ›å»º/æ›´æ–°
- [ ] Runbook åˆ›å»º/æ›´æ–°ï¼ˆStory çº§åˆ«ï¼‰
- [ ] docs/stories/_index.yaml å·²æ›´æ–°ï¼ˆå¦‚æœ‰æ–° Storyï¼‰
- [ ] è¦†ç›–ç‡æ›´æ–° docs/test-coverage/_index.yaml
- [ ] npm run validate:docs æ— é”™è¯¯
- [ ] Card çŠ¶æ€æ›´æ–°ä¸º "Done"
```

---

### 2025-12-30: ä¿¡æ¯æºé€‰æ‹©ä¸ Runbook é‡æ–°å®šä½ (CASE-006)

**Problem Identified**: AI å›ç­”ä¸šåŠ¡æµç¨‹é—®é¢˜æ—¶ç»™å‡ºé”™è¯¯çš„ APIï¼Œå› ä¸ºç›´æ¥æœç´¢ä»£ç æ‰¾åˆ°äº†åºŸå¼ƒçš„æ¥å£ã€‚

**Scenario**: ç”¨æˆ·é—®"æ‰«ç æ ¸é”€çš„æµç¨‹æ˜¯ä»€ä¹ˆ"

**AI Failure**:
1. ç”¨æˆ·é—®ä¸šåŠ¡æµç¨‹
2. AI ç›´æ¥æœç´¢ä»£ç  `grep "validate\|verify" src/modules/operators/`
3. æ‰¾åˆ°åºŸå¼ƒçš„ API `/operators/validate-ticket`ã€`/operators/verify-ticket`
4. è¿”å›é”™è¯¯ç­”æ¡ˆ
5. ç”¨æˆ·çº æ­£ï¼šæ­£ç¡®çš„æ˜¯ `/operators/login` â†’ `/qr/decrypt` â†’ `/venue/scan`

**Root Cause Analysis**:
- SKILL.md çš„ `Explanation ç±»å‹ â†’ ç›´æ¥å›ç­”` è¢«è¯¯è§£ä¸ºä¸éœ€è¦æŸ¥ä»»ä½•èµ„æ–™
- æ²¡æœ‰å®šä¹‰"å›ç­”ä¸šåŠ¡æµç¨‹é—®é¢˜åº”è¯¥æŸ¥ä»€ä¹ˆ"
- ç›´æ¥æœç´¢ä»£ç å®¹æ˜“æ‰¾åˆ°åºŸå¼ƒ/æœªä½¿ç”¨çš„ä»£ç 

**Discovery - ä¿¡æ¯åˆ†å±‚æ¶æ„**:

| å±‚çº§ | ä¿¡æ¯æº | æä¾›å†…å®¹ |
|------|--------|----------|
| ç´¢å¼•å±‚ | Story `_index.yaml` | API è°ƒç”¨é¡ºåºï¼ˆ`sequence`ï¼‰|
| å¥‘çº¦å±‚ | Card `*.md` | API è·¯å¾„ï¼ˆ`oas_paths`ï¼‰|
| å®ç°å±‚ | ä»£ç  `src/` | å†…éƒ¨ä¸šåŠ¡é€»è¾‘ |

**Key Insight**: Story çš„ `sequence` å­—æ®µ + Card çš„ `oas_paths` å·²ç»èƒ½ç¡®å®šæ­£ç¡®çš„ API åˆ—è¡¨ï¼Œä¸éœ€è¦ Runbookã€‚

**Improvements Made**:

1. **æ·»åŠ  Step 0.1.5 ä¿¡æ¯æºé€‰æ‹©**:
   ```
   | é—®é¢˜ç±»å‹ | æŸ¥è¯¢é¡ºåº |
   |----------|----------|
   | ä¸šåŠ¡æµç¨‹ | Story â†’ Card â†’ ä»£ç  |
   | API ç”¨æ³• | Card â†’ ä»£ç  |
   | é¡¹ç›®çŠ¶æ€ | /ai-sitemap |
   | ä»£ç ç»†èŠ‚ | ä»£ç  |
   ```

2. **Runbook åˆ†æä¸é‡æ–°å®šä½**:
   - åˆ†æå‘ç° Runbook ~70% å†…å®¹ä¸ Story/Card/Newman é‡å¤
   - QA Checklist å·²è¢« `/tests` é¡µé¢æ›¿ä»£
   - é‡æ–°å®šä½ä¸º"å‰ç«¯å¯¹æ¥æ–‡æ¡£"
   - æ›´æ–° `references/runbook.md` è§„èŒƒ

3. **åˆ é™¤æ—§ Runbook**:
   - Runbook æ˜¯æ´¾ç”Ÿæ–‡æ¡£ï¼ˆåŸºäº Story + Card ç”Ÿæˆï¼‰
   - ä¿¡æ¯æºåœ¨ Story + Card ä¸­ï¼Œåˆ é™¤ä¸ä¸¢å¤±ä¿¡æ¯
   - åˆ é™¤ 22 ä¸ª `*-runbook.md` æ–‡ä»¶

**Files Changed**:
- `.claude/skills/ai-workflow/SKILL.md` - æ·»åŠ  Step 0.1.5ï¼Œæ›´æ–° Runbook å¼•ç”¨
- `.claude/skills/ai-workflow/references/runbook.md` - é‡å†™ä¸ºå‰ç«¯å¯¹æ¥æ–‡æ¡£è§„èŒƒ
- `docs/integration/*-runbook.md` - åˆ é™¤ 22 ä¸ªæ–‡ä»¶

**What Worked**:
- âœ… åˆ†æç°æœ‰æ–‡æ¡£ç»“æ„å‘ç° Story `sequence` å·²æœ‰ä»·å€¼
- âœ… åˆ†æ Runbook ä¸å…¶ä»–æ–‡æ¡£çš„é‡å æ‰¾åˆ°çœŸæ­£é—®é¢˜
- âœ… å‘ç° QA Checklist å·²è¢« `/tests` æ›¿ä»£

**What Didn't Work**:
- âŒ åªå®šä¹‰äº†æ–°è§„èŒƒï¼Œä½†æ²¡æœ‰åˆ›å»ºå®é™…çš„å‰ç«¯å¯¹æ¥æ–‡æ¡£
- âŒ åˆ é™¤å‰æœªè¯„ä¼°æ˜¯å¦æœ‰åŠŸèƒ½éœ€è¦æ–°æ–‡æ¡£

**Key Learning**:
1. **æŸ¥è¯¢é¡ºåºæ¯”ç¦æ­¢æ›´æœ‰æ•ˆ** - ä¸æ˜¯"ç¦æ­¢æœç´¢ä»£ç "ï¼Œè€Œæ˜¯"å…ˆ Story â†’ Card ç¡®å®š APIï¼Œå†çœ‹ä»£ç "
2. **æ´¾ç”Ÿæ–‡æ¡£å¯ä»¥åˆ é™¤** - ä¿¡æ¯æºåœ¨ä¸Šæ¸¸ï¼Œæ´¾ç”Ÿæ–‡æ¡£æ²¡æœ‰ç‹¬ç‰¹ä»·å€¼æ—¶å¯åºŸå¼ƒ
3. **é‡æ–°å®šä½æ¯”åºŸå¼ƒæ›´å¥½** - Runbook ä½œä¸ºå‰ç«¯å¯¹æ¥æ–‡æ¡£æœ‰æ–°ä»·å€¼

**Open Question**:
- æ˜¯å¦éœ€è¦æŒ‰æ–°è§„èŒƒåˆ›å»ºå‰ç«¯å¯¹æ¥æ–‡æ¡£ï¼Ÿä½•æ—¶åˆ›å»ºï¼Ÿ

---

### 2025-12-30: Story åˆ›å»ºæ—¶é—æ¼ _index.yaml åŒæ­¥ (CASE-007)

**Problem Identified**: åˆ›å»º US-019 Story æ—¶ï¼ŒæœªåŒæ—¶æ›´æ–° `docs/stories/_index.yaml`ã€‚

**Scenario**: åˆ›å»º OTA æ“ä½œå‘˜ç®¡ç† Story (US-019)

**AI Failure**:
1. åˆ›å»ºäº† `docs/stories/US-019-ota-operator-management.md`
2. åˆ›å»ºäº† `docs/cards/ota-operator-management.md`
3. **æœªæ›´æ–° `docs/stories/_index.yaml`**
4. å¯¼è‡´ Step 0.1.5 ä¿¡æ¯æºé€‰æ‹©æ— æ³•å‘ç°è¯¥ Story

**Root Cause Analysis**:
- SKILL.md Step 2 åªè¯´"æ‰§è¡Œå¼€å‘"ï¼Œæ²¡æœ‰ Story åˆ›å»ºæ­¥éª¤æ¸…å•
- Step 3 å®Œæˆæ£€æŸ¥æ¸…å•æ²¡æœ‰ "_index.yaml åŒæ­¥æ£€æŸ¥"
- Card åˆ›å»ºæœ‰å®Œæ•´æ­¥éª¤ï¼ˆStep 3.3.1ï¼‰ï¼Œä½† Story åˆ›å»ºæ²¡æœ‰

**å¯¹æ¯”**:
| æ–‡æ¡£ç±»å‹ | åˆ›å»ºæ­¥éª¤æ¸…å• | ç´¢å¼•åŒæ­¥è¦æ±‚ |
|----------|-------------|-------------|
| Card | âœ… Step 3.3.1 æœ‰å®Œæ•´æ­¥éª¤ | âœ… æœ‰ `_index.yaml` åŒæ­¥ |
| Story | âŒ æ— æ˜ç¡®æ­¥éª¤ | âŒ æ— æ˜ç¡®è¦æ±‚ |

**Improvements Made**:

1. **æ·»åŠ  Step 2.1 Story åˆ›å»ºæ­¥éª¤**:
   - åˆ›å»º Story æ–‡ä»¶
   - æ›´æ–° `docs/stories/_index.yaml`
   - éªŒè¯ç´¢å¼•åŒæ­¥

2. **åœ¨ Step 3 å®Œæˆæ£€æŸ¥æ¸…å•æ·»åŠ **:
   - `[ ] Story ç´¢å¼•åŒæ­¥ docs/stories/_index.yamlï¼ˆå¦‚åˆ›å»º/ä¿®æ”¹äº† Storyï¼‰`

**Files Changed**:
- `.claude/skills/ai-workflow/SKILL.md` - æ·»åŠ  Step 2.1 + Step 3 æ£€æŸ¥é¡¹

**Key Learning**:
1. **æ–‡æ¡£åˆ›å»ºä¸ç´¢å¼•åŒæ­¥å¿…é¡»æˆå¯¹** - åˆ›å»ºæ–‡æ¡£åç«‹å³æ›´æ–°å¯¹åº”ç´¢å¼•
2. **å¯¹ç§°è®¾è®¡** - Story åˆ›å»ºæ­¥éª¤åº”ä¸ Card åˆ›å»ºæ­¥éª¤åŒç­‰è¯¦ç»†
3. **æ˜¾å¼æ£€æŸ¥æ¸…å•** - ä¾èµ– AI è®°å¿†ä¸å¯é ï¼Œå¿…é¡»åœ¨å·¥ä½œæµä¸­æ˜¾å¼åˆ—å‡º

---

*This case study documents our journey to discover effective AI-guided development workflows. Key insight: Balance simple verification with systematic analysis - use the right tool for the right complexity level, but always verify reality first. **Core learning: Test every pattern immediately - even patterns about testing patterns. Checklists must be explicit - relying on AI memory is unreliable. Query order matters - Story â†’ Card â†’ Code prevents finding deprecated APIs.***